{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Cálculo de Métricas de Avaliação de Aprendizado**\n",
        "\n",
        "Este projeto tem como objetivo calcular as principais métricas utilizadas para avaliar modelos de classificação binária. As métricas implementadas serão:\n",
        "\n",
        "- Acurácia  \n",
        "- Precisão  \n",
        "- Sensibilidade (Recall)  \n",
        "- Especificidade  \n",
        "- F-score  \n",
        "\n",
        "Utilizaremos valores simulados em uma matriz de confusão para compreender, na prática, como cada métrica funciona.\n"
      ],
      "metadata": {
        "id": "hSzdCpGqnYrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 1: Definindo os valores da matriz de confusão**\n",
        "\n",
        "Vamos utilizar valores fictícios para construir uma matriz de confusão. Esses valores representam a quantidade de acertos e erros do modelo de classificação."
      ],
      "metadata": {
        "id": "jZ8U-wL0nxjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo os valores das métricas de confusão\n",
        "VP = 80  # Verdadeiros Positivos\n",
        "FP = 10  # Falsos Positivos\n",
        "FN = 5   # Falsos Negativos\n",
        "VN = 50  # Verdadeiros Negativos"
      ],
      "metadata": {
        "id": "dLAITcARoBJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 2: Criando funções para cálculo das métricas**\n",
        "\n",
        "Agora, vamos implementar funções em Python para calcular as métricas com base nas fórmulas clássicas:\n",
        "- Acurácia\n",
        "- Precisão\n",
        "- Sensibilidade (Recall)\n",
        "- Especificidade\n",
        "- F-score"
      ],
      "metadata": {
        "id": "UB6d2-AMoJWD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kcHzv-oqmkXF"
      },
      "outputs": [],
      "source": [
        "def acuracia(vp, fp, fn, vn):\n",
        "    return (vp + vn) / (vp + fp + fn + vn)\n",
        "\n",
        "def precisao(vp, fp):\n",
        "    return vp / (vp + fp)\n",
        "\n",
        "def recall(vp, fn):\n",
        "    return vp / (vp + fn)\n",
        "\n",
        "def especificidade(vn, fp):\n",
        "    return vn / (vn + fp)\n",
        "\n",
        "def f_score(precisao, recall):\n",
        "    return 2 * (precisao * recall) / (precisao + recall)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 3: Calculando as métricas**\n",
        "\n",
        "Com os valores definidos e as funções implementadas, vamos agora realizar os cálculos para obter os resultados de cada métrica.\n"
      ],
      "metadata": {
        "id": "uYGNzFdioTy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = acuracia(VP, FP, FN, VN)\n",
        "prec = precisao(VP, FP)\n",
        "rec = recall(VP, FN)\n",
        "esp = especificidade(VN, FP)\n",
        "fscore = f_score(prec, rec)"
      ],
      "metadata": {
        "id": "N5-eXhqkmsyM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passo 4: Exibindo os resultados**\n",
        "\n",
        "Por fim, vamos mostrar os valores calculados de cada métrica com duas casas decimais, para facilitar a visualização.\n"
      ],
      "metadata": {
        "id": "v3kA7gYrogwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Acurácia: {acc:.2f}\")\n",
        "print(f\"Precisão: {prec:.2f}\")\n",
        "print(f\"Recall (Sensibilidade): {rec:.2f}\")\n",
        "print(f\"Especificidade: {esp:.2f}\")\n",
        "print(f\"F-Score: {fscore:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJQQ6bKimtAf",
        "outputId": "fc55a90c-b740-41f1-cfa4-1ecca8161c66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 0.90\n",
            "Precisão: 0.89\n",
            "Recall (Sensibilidade): 0.94\n",
            "Especificidade: 0.83\n",
            "F-Score: 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com esse projeto simples, conseguimos visualizar como calcular manualmente as principais métricas de avaliação para modelos de classificação. Cada uma delas ajuda a interpretar diferentes aspectos do desempenho de um modelo."
      ],
      "metadata": {
        "id": "AU0I5kqEosbK"
      }
    }
  ]
}